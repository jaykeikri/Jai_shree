{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbwkovR6TQ9csINtOw9vpo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaykeikri/Jai_shree/blob/main/RECAP_ACTIVITIES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foIubHhUtOyH",
        "outputId": "6e6641c9-3b72-4b33-ba84-7cbc9ccfa8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Classification (Breast Cancer)\n",
            "Accuracy: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "# Binary Classification Example\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_breast_cancer(return_X_y=True)  # 0 = malignant, 1 = benign\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test\n",
        "print(\"Binary Classification (Breast Cancer)\")\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Class Classification Example\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_iris(return_X_y=True)  # 3 classes of flowers\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Test\n",
        "print(\"\\nMulti-Class Classification (Iris)\")\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_JQL7nctUaN",
        "outputId": "93867599-848a-4525-d231-8eaf3c3c0559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-Class Classification (Iris)\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Regression Example\n",
        "# Predict house price from house size (sqft)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Step 1: Tiny dataset (Size vs Price)\n",
        "X = [[500], [1000], [1500], [2000], [2500]]   # Size of house\n",
        "y = [50, 100, 150, 200, 250]                  # Price in '000s\n",
        "\n",
        "# Step 2: Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Step 3: Predict new values\n",
        "print(\"Predict price for 1200 sqft:\", model.predict([[1200]]))\n",
        "print(\"Predict price for 2200 sqft:\", model.predict([[2200]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucYuSlY4tbXt",
        "outputId": "a7c39ee3-a224-4071-858e-cc7e5c1acc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict price for 1200 sqft: [120.]\n",
            "Predict price for 2200 sqft: [220.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Clustering Example with K-Means\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Small dataset (X, Y coordinates)\n",
        "X = np.array([\n",
        "    [1, 2], [1, 4], [1, 0],\n",
        "    [10, 2], [10, 4], [10, 0]\n",
        "])\n",
        "\n",
        "# Step 2: Apply KMeans clustering (2 clusters)\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Step 3: Show cluster centers and labels\n",
        "print(\"Cluster Centers:\\n\", kmeans.cluster_centers_)\n",
        "print(\"Labels for each point:\", kmeans.labels_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE_WaDDrtoLn",
        "outputId": "fa009dd7-e8e4-4ff6-eab3-1637f6d741fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers:\n",
            " [[ 1.  2.]\n",
            " [10.  2.]]\n",
            "Labels for each point: [0 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# End-to-End ML Pipeline (Multi-Class Classification)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Step 2: Split into train & test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3: Build pipeline (scaling + model)\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),                 # Preprocessing\n",
        "    (\"model\", LogisticRegression(max_iter=1000))  # Classification model\n",
        "])\n",
        "\n",
        "# Step 4: Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Predictions\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "# Step 7: Predict new sample\n",
        "sample = [[5.1, 3.5, 1.4, 0.2]]  # Example flower\n",
        "print(\"\\nPrediction for sample:\", iris.target_names[pipeline.predict(sample)[0]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WegDDCfZt_d7",
        "outputId": "5d735989-e2e6-411c-a0c7-b3257079cf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "\n",
            "Prediction for sample: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Neural Network for Iris Classification\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Step 1: Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target   # Features and labels\n",
        "\n",
        "# Step 2: Preprocess (scale + one-hot encode labels)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = to_categorical(y)  # Convert labels to one-hot encoding\n",
        "\n",
        "# Step 3: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4: Build a simple Neural Network\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation=\"relu\", input_shape=(4,)),  # hidden layer\n",
        "    tf.keras.layers.Dense(8, activation=\"relu\"),                     # hidden layer\n",
        "    tf.keras.layers.Dense(3, activation=\"softmax\")                   # output layer (3 classes)\n",
        "])\n",
        "\n",
        "# Step 5: Compile model\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Step 6: Train model\n",
        "model.fit(X_train, y_train, epochs=50, verbose=0)\n",
        "\n",
        "# Step 7: Evaluate model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Step 8: Predict new sample\n",
        "sample = scaler.transform([[5.1, 3.5, 1.4, 0.2]])\n",
        "prediction = model.predict(sample)\n",
        "print(\"Predicted class:\", iris.target_names[prediction.argmax()])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCHNvXgEvurb",
        "outputId": "0f0f25c4-2869-4ef9-c6bd-a4369752a6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
            "Predicted class: setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression Example\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Data: size of house (sqft) vs price (in '000s)\n",
        "X = [[500], [1000], [1500], [2000], [2500]]\n",
        "y = [50, 100, 150, 200, 250]\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "print(\"Price for 1200 sqft:\", model.predict([[1200]]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu8kygOhyP_d",
        "outputId": "2fa16492-24ed-4374-f96e-d77157dc49aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price for 1200 sqft: [120.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Example\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Data: age vs disease (0 = no, 1 = yes)\n",
        "X = [[20], [25], [30], [35], [40], [45], [50], [55]]\n",
        "y = [0, 0, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict\n",
        "print(\"Disease for age 28:\", model.predict([[28]]))  # expect 0\n",
        "print(\"Disease for age 48:\", model.predict([[48]]))  # expect 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V9IlZpDyjNL",
        "outputId": "0dab379f-968c-4a58-8728-1daf6867d27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disease for age 28: [0]\n",
            "Disease for age 48: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Data: size (X) vs price (y)\n",
        "X = torch.tensor([[500.0], [1000.0], [1500.0], [2000.0], [2500.0]])\n",
        "y = torch.tensor([[50.0], [100.0], [150.0], [200.0], [250.0]])\n",
        "\n",
        "# Model: Linear Regression\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    # Forward\n",
        "    pred = model(X)\n",
        "    loss = criterion(pred, y)\n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Test prediction\n",
        "test = torch.tensor([[1200.0]])\n",
        "print(\"Price for 1200 sqft:\", model(test).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFSFDmZ0ygQw",
        "outputId": "0ce833b0-6abf-482f-a4ff-f47dec56158d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price for 1200 sqft: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Data: age (X) vs disease (y)\n",
        "X = torch.tensor([[20.0], [25.0], [30.0], [35.0], [40.0], [45.0], [50.0], [55.0]])\n",
        "y = torch.tensor([[0.0], [0.0], [0.0], [0.0], [1.0], [1.0], [1.0], [1.0]])\n",
        "\n",
        "# Model: Logistic Regression\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    pred = model(X)\n",
        "    loss = criterion(pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Test prediction\n",
        "test1 = torch.tensor([[28.0]])\n",
        "test2 = torch.tensor([[48.0]])\n",
        "print(\"Disease (age 28):\", model(test1).item())\n",
        "print(\"Disease (age 48):\", model(test2).item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlMVmnDczHTO",
        "outputId": "bb36a716-a7df-4509-995d-6cf787a74073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disease (age 28): 0.9674901366233826\n",
            "Disease (age 48): 0.9986226558685303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Step 1: Load MNIST dataset (images of digits 0–9)\n",
        "transform = transforms.ToTensor()\n",
        "train_data = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# Step 2: Define a simple CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3)   # 1 input channel (grayscale), 8 filters, 3x3 kernel\n",
        "        self.fc1 = nn.Linear(8*26*26, 10) # output = 10 classes (digits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = x.view(-1, 8*26*26)   # flatten\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "# Step 3: Train one batch (for demo)\n",
        "model = SimpleCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    break   # just one batch for demo\n",
        "\n",
        "print(\"CNN training step complete ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLMQMkTuzOd9",
        "outputId": "1bfb8b38-5e98-48a0-da41-977236d70356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 34.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.10MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 7.95MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.82MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN training step complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple RNN Example (sequence data)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Step 1: Fake sequence dataset (each sample = sequence of 5 numbers)\n",
        "X = torch.tensor([\n",
        "    [[1.0],[2.0],[3.0],[4.0],[5.0]],\n",
        "    [[2.0],[3.0],[4.0],[5.0],[6.0]]\n",
        "])   # shape (2 samples, 5 timesteps, 1 feature)\n",
        "\n",
        "y = torch.tensor([0, 1])   # labels for demo\n",
        "\n",
        "# Step 2: Define RNN\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size=1, hidden_size=4, batch_first=True)\n",
        "        self.fc = nn.Linear(4, 2)   # 2 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = out[:, -1, :]   # last time step\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# Step 3: Run model\n",
        "model = SimpleRNN()\n",
        "outputs = model(X)\n",
        "print(\"RNN output:\", outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwvQ2y24zYvy",
        "outputId": "348980bb-e605-4d88-9c13-b274c9cb7a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN output: tensor([[-0.8082, -0.0866],\n",
            "        [-0.7809, -0.0778]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B6Nik6zgzi0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}